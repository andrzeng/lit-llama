{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andrew/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/usr/lib/python3/dist-packages/pkg_resources/__init__.py:116: PkgResourcesDeprecationWarning: 1.1build1 is an invalid version and will not be supported in a future release\n",
      "  warnings.warn(\n",
      "/usr/lib/python3/dist-packages/pkg_resources/__init__.py:116: PkgResourcesDeprecationWarning: 0.1.43ubuntu1 is an invalid version and will not be supported in a future release\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import lightning as L\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from lit_llama import model\n",
    "import random\n",
    "from lit_llama import LLaMA, Tokenizer\n",
    "from lit_llama.utils import EmptyInitOnDevice, lazy_load, llama_model_lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/pkg_resources/__init__.py:116: PkgResourcesDeprecationWarning: 1.1build1 is an invalid version and will not be supported in a future release\n",
      "  warnings.warn(\n",
      "/usr/lib/python3/dist-packages/pkg_resources/__init__.py:116: PkgResourcesDeprecationWarning: 0.1.43ubuntu1 is an invalid version and will not be supported in a future release\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "fabric = L.Fabric(devices=1)\n",
    "tokenizer_path: Path = Path(\"checkpoints/lit-llama/tokenizer.model\")\n",
    "tokenizer = Tokenizer(tokenizer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open('datasets/alpaca_data_cleaned.json') as f:\n",
    "    alpaca_json = json.load(f)\n",
    "\n",
    "# Create tokenized j\n",
    "alpaca_json_tokens = []\n",
    "\n",
    "for item in alpaca_json:\n",
    "    alpaca_json_tokens.append(\n",
    "        {\n",
    "            'instruction': tokenizer.encode(item['instruction'], bos=True, eos=False, device=fabric.device),\n",
    "            'input': tokenizer.encode(item['input'], bos=False, eos=False, device=fabric.device),\n",
    "            'output':tokenizer.encode(item['output'], bos=False, eos=True, device=fabric.device)\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_batch(batch_size=10):\n",
    "    batch_indices = random.sample(range(len(alpaca_json_tokens)), k=batch_size)\n",
    "    batch_indices=[1]\n",
    "    \n",
    "    # IST tokens\n",
    "    IST_tokens = []\n",
    "    for index in batch_indices:\n",
    "        llama_input = torch.cat([alpaca_json_tokens[index]['instruction'], alpaca_json_tokens[index]['input']]).unsqueeze(0)\n",
    "        IST_tokens.append(IST_generator(LLamaModel(llama_input)[1])[:,-1,:])\n",
    "\n",
    "    # get shortest\n",
    "    shortest_output_len = 1000\n",
    "    for item in batch_indices:\n",
    "        if(len(alpaca_json_tokens[item]['output']) < shortest_output_len):\n",
    "            shortest_output_len = len(alpaca_json_tokens[item]['output'])\n",
    "\n",
    "\n",
    "    length = random.randint(0,shortest_output_len-1)\n",
    "    inputs = []\n",
    "    targets = []\n",
    "\n",
    "    for item in batch_indices:\n",
    "        inputs.append(alpaca_json_tokens[item]['output'][:length])\n",
    "        targets.append(alpaca_json_tokens[item]['output'][:length+1])\n",
    "    \n",
    "    return torch.stack(inputs), torch.stack(targets), torch.stack(IST_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "checkpoint_path: Path = Path(\"checkpoints/lit-llama/7B/lit-llama.pth\")\n",
    "tokenizer_path: Path = Path(\"checkpoints/lit-llama/tokenizer.model\")\n",
    "\n",
    "\n",
    "def load_LLaMA(checkpoint_path):\n",
    "    with lazy_load(checkpoint_path) as checkpoint:\n",
    "        name = llama_model_lookup(checkpoint)\n",
    "\n",
    "        with EmptyInitOnDevice(\n",
    "                device=fabric.device, dtype=dtype, quantization_mode=None # We won't quantize the weights\n",
    "        ):\n",
    "            model = LLaMA.from_name(name)\n",
    "\n",
    "        model.load_state_dict(checkpoint)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading models...\n",
      "Finished loading the first model\n",
      "Finished loading models\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dtype = torch.bfloat16 if fabric.device.type == \"cuda\" and torch.cuda.is_bf16_supported() else torch.float32\n",
    "\n",
    "LLaMA_config = model.LLaMAConfig.from_name('7B')\n",
    "print('Loading models...')\n",
    "# Load the LLaMa model and the IST generator (also a LLaMA model)\n",
    "LLamaModel = load_LLaMA(checkpoint_path).to(fabric.device)\n",
    "#LLamaModel = LLaMA(LLaMA_config)\n",
    "print('Finished loading the first model')\n",
    "print('Finished loading models')\n",
    "tokenizer = Tokenizer(tokenizer_path)\n",
    "\n",
    "IST_schemes = ['vanilla', 'last 4', '2nd to last', 'all layers']\n",
    "scheme_losses = {}\n",
    "\n",
    "IST_generator = model.Block(LLaMA_config)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(IST_generator.parameters(), lr=1e-4)\n",
    "IST_generator = IST_generator.to(fabric.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in LLamaModel.parameters():\n",
    "    param.requires_grad=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(IST_generator.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch0, loss: 1.8046875\n",
      "epoch1, loss: 1.75\n",
      "epoch2, loss: 3.671875\n",
      "epoch3, loss: 1.3984375\n",
      "epoch4, loss: 1.375\n",
      "epoch5, loss: 1.46875\n",
      "epoch6, loss: 2.859375\n",
      "epoch7, loss: 1.1640625\n",
      "epoch8, loss: 1.1875\n",
      "epoch9, loss: 1.3515625\n",
      "epoch10, loss: 1.3515625\n",
      "epoch11, loss: 1.15625\n",
      "epoch12, loss: 0.94921875\n",
      "epoch13, loss: 3.203125\n",
      "epoch14, loss: 0.83984375\n",
      "epoch15, loss: 0.9296875\n",
      "epoch16, loss: 1.2578125\n",
      "epoch17, loss: 0.78125\n",
      "epoch18, loss: 1.2421875\n",
      "epoch19, loss: 0.77734375\n",
      "epoch20, loss: 0.97265625\n",
      "epoch21, loss: 1.21875\n",
      "epoch22, loss: 0.5234375\n",
      "epoch23, loss: 1.0703125\n",
      "epoch24, loss: 0.54296875\n",
      "epoch25, loss: 1.0078125\n",
      "epoch26, loss: 1.078125\n",
      "epoch27, loss: 0.462890625\n",
      "epoch28, loss: 0.49609375\n",
      "epoch29, loss: 0.515625\n",
      "epoch30, loss: 0.451171875\n",
      "epoch31, loss: 0.1640625\n",
      "epoch32, loss: 1.0078125\n",
      "epoch33, loss: 0.16796875\n",
      "epoch34, loss: 0.64453125\n",
      "epoch35, loss: 0.86328125\n",
      "epoch36, loss: 0.58984375\n",
      "epoch37, loss: 0.61328125\n",
      "epoch38, loss: 0.84375\n",
      "epoch39, loss: 0.203125\n",
      "epoch40, loss: 0.73046875\n",
      "epoch41, loss: 0.78125\n",
      "epoch42, loss: 0.828125\n",
      "epoch43, loss: 0.16796875\n",
      "epoch44, loss: 0.032958984375\n",
      "epoch45, loss: 0.68359375\n",
      "epoch46, loss: 0.7265625\n",
      "epoch47, loss: 0.244140625\n",
      "epoch48, loss: 0.042724609375\n",
      "epoch49, loss: 0.04931640625\n",
      "epoch50, loss: 0.0849609375\n",
      "epoch51, loss: 0.671875\n",
      "epoch52, loss: 0.439453125\n",
      "epoch53, loss: 0.58984375\n",
      "epoch54, loss: 0.494140625\n",
      "epoch55, loss: 0.4609375\n",
      "epoch56, loss: 0.208984375\n",
      "epoch57, loss: 0.0269775390625\n",
      "epoch58, loss: 0.4296875\n",
      "epoch59, loss: 0.0478515625\n",
      "epoch60, loss: 0.134765625\n",
      "epoch61, loss: 0.01519775390625\n",
      "epoch62, loss: 0.01544189453125\n",
      "epoch63, loss: 0.0162353515625\n",
      "epoch64, loss: 0.051025390625\n",
      "epoch65, loss: 0.0123291015625\n",
      "epoch66, loss: 0.224609375\n",
      "epoch67, loss: 0.01385498046875\n",
      "epoch68, loss: 0.1435546875\n",
      "epoch69, loss: 0.0203857421875\n",
      "epoch70, loss: 0.0272216796875\n",
      "epoch71, loss: 0.04931640625\n",
      "epoch72, loss: 0.0115966796875\n",
      "epoch73, loss: 0.09619140625\n",
      "epoch74, loss: 0.09619140625\n",
      "epoch75, loss: 0.12451171875\n",
      "epoch76, loss: 0.05859375\n",
      "epoch77, loss: 0.10302734375\n",
      "epoch78, loss: 0.01171875\n",
      "epoch79, loss: 0.01043701171875\n",
      "epoch80, loss: 0.029296875\n",
      "epoch81, loss: 0.01055908203125\n",
      "epoch82, loss: 0.004913330078125\n",
      "epoch83, loss: 0.02294921875\n",
      "epoch84, loss: 0.021484375\n",
      "epoch85, loss: 0.01708984375\n",
      "epoch86, loss: 0.0164794921875\n",
      "epoch87, loss: 0.004913330078125\n",
      "epoch88, loss: 0.00732421875\n",
      "epoch89, loss: 0.0125732421875\n",
      "epoch90, loss: 0.00830078125\n",
      "epoch91, loss: 0.01019287109375\n",
      "epoch92, loss: 0.00408935546875\n",
      "epoch93, loss: 0.006072998046875\n",
      "epoch94, loss: 0.0087890625\n",
      "epoch95, loss: 0.004730224609375\n",
      "epoch96, loss: 0.0057373046875\n",
      "epoch97, loss: 0.0068359375\n",
      "epoch98, loss: 0.007171630859375\n",
      "epoch99, loss: 0.00653076171875\n",
      "epoch100, loss: 0.006683349609375\n",
      "epoch101, loss: 0.0031280517578125\n",
      "epoch102, loss: 0.005523681640625\n",
      "epoch103, loss: 0.005584716796875\n",
      "epoch104, loss: 0.00341796875\n",
      "epoch105, loss: 0.1552734375\n",
      "epoch106, loss: 0.0027008056640625\n",
      "epoch107, loss: 0.0027618408203125\n",
      "epoch108, loss: 0.003082275390625\n",
      "epoch109, loss: 0.00311279296875\n",
      "epoch110, loss: 0.0086669921875\n",
      "epoch111, loss: 0.0164794921875\n",
      "epoch112, loss: 0.0162353515625\n",
      "epoch113, loss: 0.005126953125\n",
      "epoch114, loss: 0.00933837890625\n",
      "epoch115, loss: 0.006195068359375\n",
      "epoch116, loss: 0.006683349609375\n",
      "epoch117, loss: 0.005889892578125\n",
      "epoch118, loss: 0.01025390625\n",
      "epoch119, loss: 0.004638671875\n",
      "epoch120, loss: 0.004119873046875\n",
      "epoch121, loss: 0.0028839111328125\n",
      "epoch122, loss: 0.00274658203125\n",
      "epoch123, loss: 0.004058837890625\n",
      "epoch124, loss: 0.005096435546875\n",
      "epoch125, loss: 0.002197265625\n",
      "epoch126, loss: 0.0025482177734375\n",
      "epoch127, loss: 0.0026397705078125\n",
      "epoch128, loss: 0.0027008056640625\n",
      "epoch129, loss: 0.0037689208984375\n",
      "epoch130, loss: 0.00323486328125\n",
      "epoch131, loss: 0.0023040771484375\n",
      "epoch132, loss: 0.0032806396484375\n",
      "epoch133, loss: 0.00506591796875\n",
      "epoch134, loss: 0.002838134765625\n",
      "epoch135, loss: 0.0019989013671875\n",
      "epoch136, loss: 0.0024871826171875\n",
      "epoch137, loss: 0.001983642578125\n",
      "epoch138, loss: 0.00286865234375\n",
      "epoch139, loss: 0.002899169921875\n",
      "epoch140, loss: 0.0015411376953125\n",
      "epoch141, loss: 0.0023040771484375\n",
      "epoch142, loss: 0.00145721435546875\n",
      "epoch143, loss: 0.0019989013671875\n",
      "epoch144, loss: 0.00182342529296875\n",
      "epoch145, loss: 0.00151824951171875\n",
      "epoch146, loss: 0.002105712890625\n",
      "epoch147, loss: 0.001251220703125\n",
      "epoch148, loss: 0.002410888671875\n",
      "epoch149, loss: 0.00125885009765625\n",
      "epoch150, loss: 0.0019378662109375\n",
      "epoch151, loss: 0.0018310546875\n",
      "epoch152, loss: 0.001129150390625\n",
      "epoch153, loss: 0.00119781494140625\n",
      "epoch154, loss: 0.00124359130859375\n",
      "epoch155, loss: 0.00118255615234375\n",
      "epoch156, loss: 0.0010986328125\n",
      "epoch157, loss: 0.00121307373046875\n",
      "epoch158, loss: 0.0016021728515625\n",
      "epoch159, loss: 0.002105712890625\n",
      "epoch160, loss: 0.004730224609375\n",
      "epoch161, loss: 0.0011444091796875\n",
      "epoch162, loss: 0.0018310546875\n",
      "epoch163, loss: 0.001434326171875\n",
      "epoch164, loss: 0.00115966796875\n",
      "epoch165, loss: 0.00182342529296875\n",
      "epoch166, loss: 0.00144195556640625\n",
      "epoch167, loss: 0.00159454345703125\n",
      "epoch168, loss: 0.0016326904296875\n",
      "epoch169, loss: 0.00148773193359375\n",
      "epoch170, loss: 0.002593994140625\n",
      "epoch171, loss: 0.0016937255859375\n",
      "epoch172, loss: 0.0012969970703125\n",
      "epoch173, loss: 0.002716064453125\n",
      "epoch174, loss: 0.00099945068359375\n",
      "epoch175, loss: 0.001434326171875\n",
      "epoch176, loss: 0.000873565673828125\n",
      "epoch177, loss: 0.00099945068359375\n",
      "epoch178, loss: 0.000957489013671875\n",
      "epoch179, loss: 0.0025634765625\n",
      "epoch180, loss: 0.0015106201171875\n",
      "epoch181, loss: 0.004486083984375\n",
      "epoch182, loss: 0.000873565673828125\n",
      "epoch183, loss: 0.001312255859375\n",
      "epoch184, loss: 0.0031280517578125\n",
      "epoch185, loss: 0.000957489013671875\n",
      "epoch186, loss: 0.00127410888671875\n",
      "epoch187, loss: 0.00083160400390625\n",
      "epoch188, loss: 0.000759124755859375\n",
      "epoch189, loss: 0.00104522705078125\n",
      "epoch190, loss: 0.00119781494140625\n",
      "epoch191, loss: 0.0025482177734375\n",
      "epoch192, loss: 0.0012054443359375\n",
      "epoch193, loss: 0.00177001953125\n",
      "epoch194, loss: 0.0025482177734375\n",
      "epoch195, loss: 0.000766754150390625\n",
      "epoch196, loss: 0.00174713134765625\n",
      "epoch197, loss: 0.000640869140625\n",
      "epoch198, loss: 0.001190185546875\n",
      "epoch199, loss: 0.001068115234375\n",
      "epoch200, loss: 0.001434326171875\n",
      "epoch201, loss: 0.0017547607421875\n",
      "epoch202, loss: 0.00070953369140625\n",
      "epoch203, loss: 0.00125885009765625\n",
      "epoch204, loss: 0.0006561279296875\n",
      "epoch205, loss: 0.00066375732421875\n",
      "epoch206, loss: 0.00104522705078125\n",
      "epoch207, loss: 0.0010223388671875\n",
      "epoch208, loss: 0.0011138916015625\n",
      "epoch209, loss: 0.00101470947265625\n",
      "epoch210, loss: 0.00080108642578125\n",
      "epoch211, loss: 0.01318359375\n",
      "epoch212, loss: 0.00055694580078125\n",
      "epoch213, loss: 0.0028839111328125\n",
      "epoch214, loss: 0.00060272216796875\n",
      "epoch215, loss: 0.00055694580078125\n",
      "epoch216, loss: 0.000606536865234375\n",
      "epoch217, loss: 0.000644683837890625\n",
      "epoch218, loss: 0.00113677978515625\n",
      "epoch219, loss: 0.001007080078125\n",
      "epoch220, loss: 0.00144195556640625\n",
      "epoch221, loss: 0.000507354736328125\n",
      "epoch222, loss: 0.000484466552734375\n",
      "epoch223, loss: 0.00110626220703125\n",
      "epoch224, loss: 0.0015411376953125\n",
      "epoch225, loss: 0.000942230224609375\n",
      "epoch226, loss: 0.0009307861328125\n",
      "epoch227, loss: 0.00067901611328125\n",
      "epoch228, loss: 0.000469207763671875\n",
      "epoch229, loss: 0.000957489013671875\n",
      "epoch230, loss: 0.000579833984375\n",
      "epoch231, loss: 0.000934600830078125\n",
      "epoch232, loss: 0.003936767578125\n",
      "epoch233, loss: 0.0012969970703125\n",
      "epoch234, loss: 0.00049591064453125\n",
      "epoch235, loss: 0.00052642822265625\n",
      "epoch236, loss: 0.000522613525390625\n",
      "epoch237, loss: 0.00136566162109375\n",
      "epoch238, loss: 0.00084686279296875\n",
      "epoch239, loss: 0.0009307861328125\n",
      "epoch240, loss: 0.000537872314453125\n",
      "epoch241, loss: 0.00092315673828125\n",
      "epoch242, loss: 0.000537872314453125\n",
      "epoch243, loss: 0.00099945068359375\n",
      "epoch244, loss: 0.00077056884765625\n",
      "epoch245, loss: 0.000484466552734375\n",
      "epoch246, loss: 0.0004730224609375\n",
      "epoch247, loss: 0.00096893310546875\n",
      "epoch248, loss: 0.0003871917724609375\n",
      "epoch249, loss: 0.0004558563232421875\n",
      "epoch250, loss: 0.000606536865234375\n",
      "epoch251, loss: 0.0005950927734375\n",
      "epoch252, loss: 0.000354766845703125\n",
      "epoch253, loss: 0.00152587890625\n",
      "epoch254, loss: 0.0003871917724609375\n",
      "epoch255, loss: 0.000667572021484375\n",
      "epoch256, loss: 0.00119781494140625\n",
      "epoch257, loss: 0.0004138946533203125\n",
      "epoch258, loss: 0.0005340576171875\n",
      "epoch259, loss: 0.000461578369140625\n",
      "epoch260, loss: 0.0007781982421875\n",
      "epoch261, loss: 0.000804901123046875\n",
      "epoch262, loss: 0.000675201416015625\n",
      "epoch263, loss: 0.000690460205078125\n",
      "epoch264, loss: 0.00037384033203125\n",
      "epoch265, loss: 0.000308990478515625\n",
      "epoch266, loss: 0.000400543212890625\n",
      "epoch267, loss: 0.000934600830078125\n",
      "epoch268, loss: 0.000751495361328125\n",
      "epoch269, loss: 0.00131988525390625\n",
      "epoch270, loss: 0.00077056884765625\n",
      "epoch271, loss: 0.000652313232421875\n",
      "epoch272, loss: 0.000675201416015625\n",
      "epoch273, loss: 0.000324249267578125\n",
      "epoch274, loss: 0.00054168701171875\n",
      "epoch275, loss: 0.0003757476806640625\n",
      "epoch276, loss: 0.00066375732421875\n",
      "epoch277, loss: 0.00037384033203125\n",
      "epoch278, loss: 0.0004673004150390625\n",
      "epoch279, loss: 0.0008087158203125\n",
      "epoch280, loss: 0.00074005126953125\n",
      "epoch281, loss: 0.00031280517578125\n",
      "epoch282, loss: 0.0005645751953125\n",
      "epoch283, loss: 0.0003643035888671875\n",
      "epoch284, loss: 0.000286102294921875\n",
      "epoch285, loss: 0.0005645751953125\n",
      "epoch286, loss: 0.0004405975341796875\n",
      "epoch287, loss: 0.000583648681640625\n",
      "epoch288, loss: 0.000308990478515625\n",
      "epoch289, loss: 0.0004177093505859375\n",
      "epoch290, loss: 0.000499725341796875\n",
      "epoch291, loss: 0.0002880096435546875\n",
      "epoch292, loss: 0.0004138946533203125\n",
      "epoch293, loss: 0.00051116943359375\n",
      "epoch294, loss: 0.0002593994140625\n",
      "epoch295, loss: 0.000568389892578125\n",
      "epoch296, loss: 0.00077056884765625\n",
      "epoch297, loss: 0.00051116943359375\n",
      "epoch298, loss: 0.00080108642578125\n",
      "epoch299, loss: 0.0003528594970703125\n",
      "epoch300, loss: 0.0026397705078125\n",
      "epoch301, loss: 0.0002803802490234375\n",
      "epoch302, loss: 0.00057220458984375\n",
      "epoch303, loss: 0.0023345947265625\n",
      "epoch304, loss: 0.0004558563232421875\n",
      "epoch305, loss: 0.0002918243408203125\n",
      "epoch306, loss: 0.000438690185546875\n",
      "epoch307, loss: 0.00067901611328125\n",
      "epoch308, loss: 0.00055694580078125\n",
      "epoch309, loss: 0.0003643035888671875\n",
      "epoch310, loss: 0.0004444122314453125\n",
      "epoch311, loss: 0.00128936767578125\n",
      "epoch312, loss: 0.0004367828369140625\n",
      "epoch313, loss: 0.000408172607421875\n",
      "epoch314, loss: 0.00091552734375\n",
      "epoch315, loss: 0.00054168701171875\n",
      "epoch316, loss: 0.0003490447998046875\n",
      "epoch317, loss: 0.0002574920654296875\n",
      "epoch318, loss: 0.000446319580078125\n",
      "epoch319, loss: 0.00025177001953125\n",
      "epoch320, loss: 0.0003719329833984375\n",
      "epoch321, loss: 0.000415802001953125\n",
      "epoch322, loss: 0.0004291534423828125\n",
      "epoch323, loss: 0.000560760498046875\n",
      "epoch324, loss: 0.00127410888671875\n",
      "epoch325, loss: 0.000560760498046875\n",
      "epoch326, loss: 0.0002994537353515625\n",
      "epoch327, loss: 0.000514984130859375\n",
      "epoch328, loss: 0.0002574920654296875\n",
      "epoch329, loss: 0.000339508056640625\n",
      "epoch330, loss: 0.000270843505859375\n",
      "epoch331, loss: 0.00052642822265625\n",
      "epoch332, loss: 0.000431060791015625\n",
      "epoch333, loss: 0.0002231597900390625\n",
      "epoch334, loss: 0.0002536773681640625\n",
      "epoch335, loss: 0.00045013427734375\n",
      "epoch336, loss: 0.0004482269287109375\n",
      "epoch337, loss: 0.000423431396484375\n",
      "epoch338, loss: 0.000347137451171875\n",
      "epoch339, loss: 0.000335693359375\n",
      "epoch340, loss: 0.0002841949462890625\n",
      "epoch341, loss: 0.000335693359375\n",
      "epoch342, loss: 0.00023746490478515625\n",
      "epoch343, loss: 0.00032806396484375\n",
      "epoch344, loss: 0.0003452301025390625\n",
      "epoch345, loss: 0.0003490447998046875\n",
      "epoch346, loss: 0.0002803802490234375\n",
      "epoch347, loss: 0.00023937225341796875\n",
      "epoch348, loss: 0.00022792816162109375\n",
      "epoch349, loss: 0.0002231597900390625\n",
      "epoch350, loss: 0.00018787384033203125\n",
      "epoch351, loss: 0.00026702880859375\n",
      "epoch352, loss: 0.00023937225341796875\n",
      "epoch353, loss: 0.00022792816162109375\n",
      "epoch354, loss: 0.00020599365234375\n",
      "epoch355, loss: 0.0002117156982421875\n",
      "epoch356, loss: 0.000522613525390625\n",
      "epoch357, loss: 0.00034332275390625\n",
      "epoch358, loss: 0.00020503997802734375\n",
      "epoch359, loss: 0.0002651214599609375\n",
      "epoch360, loss: 0.0001773834228515625\n",
      "epoch361, loss: 0.000408172607421875\n",
      "epoch362, loss: 0.0004062652587890625\n",
      "epoch363, loss: 0.00017547607421875\n",
      "epoch364, loss: 0.00021648406982421875\n",
      "epoch365, loss: 0.00021648406982421875\n",
      "epoch366, loss: 0.0002803802490234375\n",
      "epoch367, loss: 0.0003681182861328125\n",
      "epoch368, loss: 0.00083160400390625\n",
      "epoch369, loss: 0.00016498565673828125\n",
      "epoch370, loss: 0.000164031982421875\n",
      "epoch371, loss: 0.0002651214599609375\n",
      "epoch372, loss: 0.0003681182861328125\n",
      "epoch373, loss: 0.000514984130859375\n",
      "epoch374, loss: 0.0002918243408203125\n",
      "epoch375, loss: 0.0003604888916015625\n",
      "epoch376, loss: 0.0002613067626953125\n",
      "epoch377, loss: 0.0001678466796875\n",
      "epoch378, loss: 0.000179290771484375\n",
      "epoch379, loss: 0.000244140625\n",
      "epoch380, loss: 0.0001506805419921875\n",
      "epoch381, loss: 0.0002193450927734375\n",
      "epoch382, loss: 0.00026702880859375\n",
      "epoch383, loss: 0.000270843505859375\n",
      "epoch384, loss: 0.00017547607421875\n",
      "epoch385, loss: 0.0002498626708984375\n",
      "epoch386, loss: 0.00016689300537109375\n",
      "epoch387, loss: 0.000156402587890625\n",
      "epoch388, loss: 0.0001430511474609375\n",
      "epoch389, loss: 0.000339508056640625\n",
      "epoch390, loss: 0.00024318695068359375\n",
      "epoch391, loss: 0.0002498626708984375\n",
      "epoch392, loss: 0.000518798828125\n",
      "epoch393, loss: 0.00018310546875\n",
      "epoch394, loss: 0.000354766845703125\n",
      "epoch395, loss: 0.000156402587890625\n",
      "epoch396, loss: 0.00016498565673828125\n",
      "epoch397, loss: 0.0001430511474609375\n",
      "epoch398, loss: 0.0001621246337890625\n",
      "epoch399, loss: 0.0732421875\n",
      "epoch400, loss: 0.00017642974853515625\n",
      "epoch401, loss: 0.00017547607421875\n",
      "epoch402, loss: 0.00025177001953125\n",
      "epoch403, loss: 0.0830078125\n",
      "epoch404, loss: 0.0003108978271484375\n",
      "epoch405, loss: 0.00075531005859375\n",
      "epoch406, loss: 0.00042724609375\n",
      "epoch407, loss: 0.007171630859375\n",
      "epoch408, loss: 0.00104522705078125\n",
      "epoch409, loss: 0.003997802734375\n",
      "epoch410, loss: 0.0015716552734375\n",
      "epoch411, loss: 0.0015106201171875\n",
      "epoch412, loss: 0.0020904541015625\n",
      "epoch413, loss: 0.0015106201171875\n",
      "epoch414, loss: 0.00139617919921875\n",
      "epoch415, loss: 0.002685546875\n",
      "epoch416, loss: 0.00160980224609375\n",
      "epoch417, loss: 0.00225830078125\n",
      "epoch418, loss: 0.002166748046875\n",
      "epoch419, loss: 0.0030670166015625\n",
      "epoch420, loss: 0.001434326171875\n",
      "epoch421, loss: 0.0031280517578125\n",
      "epoch422, loss: 0.00156402587890625\n",
      "epoch423, loss: 0.00104522705078125\n",
      "epoch424, loss: 0.00110626220703125\n",
      "epoch425, loss: 0.001434326171875\n",
      "epoch426, loss: 0.0008544921875\n",
      "epoch427, loss: 0.0020904541015625\n",
      "epoch428, loss: 0.0011444091796875\n",
      "epoch429, loss: 0.00086212158203125\n",
      "epoch430, loss: 0.0010223388671875\n",
      "epoch431, loss: 0.00154876708984375\n",
      "epoch432, loss: 0.00127410888671875\n",
      "epoch433, loss: 0.00122833251953125\n",
      "epoch434, loss: 0.0014801025390625\n",
      "epoch435, loss: 0.000881195068359375\n",
      "epoch436, loss: 0.000766754150390625\n",
      "epoch437, loss: 0.000926971435546875\n",
      "epoch438, loss: 0.011474609375\n",
      "epoch439, loss: 0.000690460205078125\n",
      "epoch440, loss: 0.00098419189453125\n",
      "epoch441, loss: 0.001068115234375\n",
      "epoch442, loss: 0.000858306884765625\n",
      "epoch443, loss: 0.00148773193359375\n",
      "epoch444, loss: 0.0010528564453125\n",
      "epoch445, loss: 0.000885009765625\n",
      "epoch446, loss: 0.00119781494140625\n",
      "epoch447, loss: 0.00131988525390625\n",
      "epoch448, loss: 0.000682830810546875\n",
      "epoch449, loss: 0.00077056884765625\n",
      "epoch450, loss: 0.00078582763671875\n",
      "epoch451, loss: 0.00183868408203125\n",
      "epoch452, loss: 0.0013427734375\n",
      "epoch453, loss: 0.00124359130859375\n",
      "epoch454, loss: 0.00064849853515625\n",
      "epoch455, loss: 0.0010986328125\n",
      "epoch456, loss: 0.0035247802734375\n",
      "epoch457, loss: 0.015625\n",
      "epoch458, loss: 0.00147247314453125\n",
      "epoch459, loss: 0.00689697265625\n",
      "epoch460, loss: 0.00069427490234375\n",
      "epoch461, loss: 0.00112152099609375\n",
      "epoch462, loss: 0.00099945068359375\n",
      "epoch463, loss: 0.000946044921875\n",
      "epoch464, loss: 0.002105712890625\n",
      "epoch465, loss: 0.000591278076171875\n",
      "epoch466, loss: 0.00191497802734375\n",
      "epoch467, loss: 0.000606536865234375\n",
      "epoch468, loss: 0.000637054443359375\n",
      "epoch469, loss: 0.00045013427734375\n",
      "epoch470, loss: 0.000514984130859375\n",
      "epoch471, loss: 0.000514984130859375\n",
      "epoch472, loss: 0.00054168701171875\n",
      "epoch473, loss: 0.000537872314453125\n",
      "epoch474, loss: 0.00063323974609375\n",
      "epoch475, loss: 0.000396728515625\n",
      "epoch476, loss: 0.0004558563232421875\n",
      "epoch477, loss: 0.000518798828125\n",
      "epoch478, loss: 0.000362396240234375\n",
      "epoch479, loss: 0.000396728515625\n",
      "epoch480, loss: 0.00037384033203125\n",
      "epoch481, loss: 0.00032806396484375\n",
      "epoch482, loss: 0.000385284423828125\n",
      "epoch483, loss: 0.00030517578125\n",
      "epoch484, loss: 0.00046539306640625\n",
      "epoch485, loss: 0.00110626220703125\n",
      "epoch486, loss: 0.000484466552734375\n",
      "epoch487, loss: 0.000278472900390625\n",
      "epoch488, loss: 0.00032806396484375\n",
      "epoch489, loss: 0.0003108978271484375\n",
      "epoch490, loss: 0.00040435791015625\n",
      "epoch491, loss: 0.0003223419189453125\n",
      "epoch492, loss: 0.0004291534423828125\n",
      "epoch493, loss: 0.0002803802490234375\n",
      "epoch494, loss: 0.001007080078125\n",
      "epoch495, loss: 0.000446319580078125\n",
      "epoch496, loss: 0.000263214111328125\n",
      "epoch497, loss: 0.000396728515625\n",
      "epoch498, loss: 0.0003871917724609375\n",
      "epoch499, loss: 0.000522613525390625\n",
      "epoch500, loss: 0.0002803802490234375\n",
      "epoch501, loss: 0.00022792816162109375\n",
      "epoch502, loss: 0.001434326171875\n",
      "epoch503, loss: 0.000377655029296875\n",
      "epoch504, loss: 0.0002956390380859375\n",
      "epoch505, loss: 0.000499725341796875\n",
      "epoch506, loss: 0.000377655029296875\n",
      "epoch507, loss: 0.0002689361572265625\n",
      "epoch508, loss: 0.0002689361572265625\n",
      "epoch509, loss: 0.0002460479736328125\n",
      "epoch510, loss: 0.00043487548828125\n",
      "epoch511, loss: 0.00034332275390625\n",
      "epoch512, loss: 0.0002231597900390625\n",
      "epoch513, loss: 0.00023555755615234375\n",
      "epoch514, loss: 0.00023651123046875\n",
      "epoch515, loss: 0.00133514404296875\n",
      "epoch516, loss: 0.001678466796875\n",
      "epoch517, loss: 0.0003108978271484375\n",
      "epoch518, loss: 0.000415802001953125\n",
      "epoch519, loss: 0.000316619873046875\n",
      "epoch520, loss: 0.0002079010009765625\n",
      "epoch521, loss: 0.00020599365234375\n",
      "epoch522, loss: 0.00020599365234375\n",
      "epoch523, loss: 0.000213623046875\n",
      "epoch524, loss: 0.0002651214599609375\n",
      "epoch525, loss: 0.000385284423828125\n",
      "epoch526, loss: 0.000247955322265625\n",
      "epoch527, loss: 0.0003070831298828125\n",
      "epoch528, loss: 0.0002460479736328125\n",
      "epoch529, loss: 0.0002689361572265625\n",
      "epoch530, loss: 0.00019931793212890625\n",
      "epoch531, loss: 0.0001983642578125\n",
      "epoch532, loss: 0.000339508056640625\n",
      "epoch533, loss: 0.000278472900390625\n",
      "epoch534, loss: 0.00023651123046875\n",
      "epoch535, loss: 0.00018024444580078125\n",
      "epoch536, loss: 0.000232696533203125\n",
      "epoch537, loss: 0.000293731689453125\n",
      "epoch538, loss: 0.0003070831298828125\n",
      "epoch539, loss: 0.0003337860107421875\n",
      "epoch540, loss: 0.00140380859375\n",
      "epoch541, loss: 0.00019741058349609375\n",
      "epoch542, loss: 0.0003204345703125\n",
      "epoch543, loss: 0.00017261505126953125\n",
      "epoch544, loss: 0.00016880035400390625\n",
      "epoch545, loss: 0.0009918212890625\n",
      "epoch546, loss: 0.00018405914306640625\n",
      "epoch547, loss: 0.0001773834228515625\n",
      "epoch548, loss: 0.0003108978271484375\n",
      "epoch549, loss: 0.0002593994140625\n",
      "epoch550, loss: 0.00089263916015625\n",
      "epoch551, loss: 0.0002574920654296875\n",
      "epoch552, loss: 0.000240325927734375\n",
      "epoch553, loss: 0.00015735626220703125\n",
      "epoch554, loss: 0.00021457672119140625\n",
      "epoch555, loss: 0.000476837158203125\n",
      "epoch556, loss: 0.00025177001953125\n",
      "epoch557, loss: 0.00018787384033203125\n",
      "epoch558, loss: 0.000530242919921875\n",
      "epoch559, loss: 0.00019073486328125\n",
      "epoch560, loss: 0.000316619873046875\n",
      "epoch561, loss: 0.0004787445068359375\n",
      "epoch562, loss: 0.000335693359375\n",
      "epoch563, loss: 0.0002307891845703125\n",
      "epoch564, loss: 0.00014591217041015625\n",
      "epoch565, loss: 0.000247955322265625\n",
      "epoch566, loss: 0.0002422332763671875\n",
      "epoch567, loss: 0.0001926422119140625\n",
      "epoch568, loss: 0.000293731689453125\n",
      "epoch569, loss: 0.00014781951904296875\n",
      "epoch570, loss: 0.000133514404296875\n",
      "epoch571, loss: 0.0002307891845703125\n",
      "epoch572, loss: 0.00024318695068359375\n",
      "epoch573, loss: 0.000499725341796875\n",
      "epoch574, loss: 0.00020885467529296875\n",
      "epoch575, loss: 0.0001468658447265625\n",
      "epoch576, loss: 0.000213623046875\n",
      "epoch577, loss: 0.00022125244140625\n",
      "epoch578, loss: 0.0001850128173828125\n",
      "epoch579, loss: 0.0002307891845703125\n",
      "epoch580, loss: 0.000186920166015625\n",
      "epoch581, loss: 0.00021266937255859375\n",
      "epoch582, loss: 0.00013637542724609375\n",
      "epoch583, loss: 0.0001354217529296875\n",
      "epoch584, loss: 0.000507354736328125\n",
      "epoch585, loss: 0.0001735687255859375\n",
      "epoch586, loss: 0.00013256072998046875\n",
      "epoch587, loss: 0.00021076202392578125\n",
      "epoch588, loss: 0.00019073486328125\n",
      "epoch589, loss: 0.0001964569091796875\n",
      "epoch590, loss: 0.000522613525390625\n",
      "epoch591, loss: 0.00021266937255859375\n",
      "epoch592, loss: 0.0001888275146484375\n",
      "epoch593, loss: 0.0002079010009765625\n",
      "epoch594, loss: 0.00119781494140625\n",
      "epoch595, loss: 0.00018596649169921875\n",
      "epoch596, loss: 0.0001659393310546875\n",
      "epoch597, loss: 0.0001621246337890625\n",
      "epoch598, loss: 0.00013446807861328125\n",
      "epoch599, loss: 0.00023937225341796875\n",
      "epoch600, loss: 0.000186920166015625\n",
      "epoch601, loss: 0.000186920166015625\n",
      "epoch602, loss: 0.0001239776611328125\n",
      "epoch603, loss: 0.0001735687255859375\n",
      "epoch604, loss: 0.00106048583984375\n",
      "epoch605, loss: 0.000133514404296875\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m IST_tokens \u001b[39m=\u001b[39m IST_tokens\u001b[39m.\u001b[39mto(fabric\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m      9\u001b[0m predicted_logits \u001b[39m=\u001b[39m LLamaModel(inputs, IST_tokens\u001b[39m.\u001b[39mtype(torch\u001b[39m.\u001b[39mbfloat16))[\u001b[39m0\u001b[39m]\n\u001b[0;32m---> 10\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(predicted_logits\u001b[39m.\u001b[39mpermute(\u001b[39m0\u001b[39m,\u001b[39m2\u001b[39m,\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mto(fabric\u001b[39m.\u001b[39mdevice), targets\u001b[39m.\u001b[39;49mtype(torch\u001b[39m.\u001b[39;49mLongTensor)\u001b[39m.\u001b[39mto(fabric\u001b[39m.\u001b[39mdevice))\n\u001b[1;32m     11\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     12\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "LLamaModel.train()\n",
    "for epoch in range(1000):\n",
    "    inputs, targets, IST_tokens = get_batch(1)\n",
    "    \n",
    "    inputs = inputs.to(fabric.device)\n",
    "    targets = targets.to(fabric.device)\n",
    "    IST_tokens = IST_tokens.to(fabric.device)\n",
    "    predicted_logits = LLamaModel(inputs, IST_tokens.type(torch.bfloat16))[0]\n",
    "    loss = loss_fn(predicted_logits.permute(0,2,1).to(fabric.device), targets.type(torch.LongTensor).to(fabric.device))\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    print(f'epoch{epoch}, loss: {loss.item()}')\n",
    "    losses.append(loss.item())\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'loss')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)\n",
    "plt.xlabel('batch')\n",
    "plt.ylabel('loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_IST(string):\n",
    "    tokens = tokenizer.encode(string).unsqueeze(0).type(torch.LongTensor).to(fabric.device)\n",
    "    x = LLamaModel(tokens)[1]\n",
    "    x = IST_generator(x)\n",
    "    return x[:,-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import generate\n",
    "out = generate.generate(model=LLamaModel, \n",
    "                  idx=tokenizer.encode('').type(torch.LongTensor).to(fabric.device), \n",
    "                  max_new_tokens=200, \n",
    "                  max_seq_length=400,top_k=1, internal_state_tokens=get_IST('What are the three primary colors?').type(torch.bfloat16))[0]\n",
    "\n",
    "print(tokenizer.decode(out))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
